"""
RAG Agent - æ™ºèƒ½ä»£ç†é‚è¼¯
æ”¯æ´å¤šæ­¥æ¨ç†ã€å·¥å…·å‘¼å«ã€ä¸²æµè¼¸å‡ºã€æ–‡ä»¶ç¯©é¸
"""

import json
import asyncio
from typing import AsyncGenerator, Optional, List
from dataclasses import dataclass, asdict
from enum import Enum
from openai import OpenAI
import os

class EventType(Enum):
    THINKING = "thinking"
    TOOL_CALL = "tool_call"
    TOOL_RESULT = "tool_result"
    ANSWER = "answer"
    SOURCE = "source"
    DONE = "done"
    ERROR = "error"

@dataclass
class AgentEvent:
    type: EventType
    content: str
    data: Optional[dict] = None
    
    def to_sse(self) -> str:
        """è½‰æ›ç‚º Server-Sent Events æ ¼å¼"""
        payload = {
            "type": self.type.value,
            "content": self.content,
        }
        if self.data:
            payload["data"] = self.data
        return f"data: {json.dumps(payload, ensure_ascii=False)}\n\n"


class RAGAgent:
    """RAG æ™ºèƒ½ä»£ç†"""
    
    def __init__(self, retriever, generator):
        self.retriever = retriever
        self.generator = generator
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        
        # å®šç¾©å¯ç”¨å·¥å…·
        self.tools = [
            {
                "type": "function",
                "function": {
                    "name": "rag_search",
                    "description": "åœ¨çŸ¥è­˜åº«ä¸­é€²è¡Œèªæ„æœå°‹ï¼Œæ‰¾å‡ºèˆ‡æŸ¥è©¢ç›¸é—œçš„æ–‡ä»¶ç‰‡æ®µ",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "query": {
                                "type": "string",
                                "description": "æœå°‹æŸ¥è©¢ï¼Œå¯ä»¥æ˜¯é—œéµå­—æˆ–è‡ªç„¶èªè¨€å•é¡Œ"
                            },
                            "top_k": {
                                "type": "integer",
                                "description": "è¿”å›çµæœæ•¸é‡ï¼Œé è¨­ 5",
                                "default": 5
                            }
                        },
                        "required": ["query"]
                    }
                }
            },
            {
                "type": "function", 
                "function": {
                    "name": "rag_search_multiple",
                    "description": "ç”¨å¤šå€‹ä¸åŒçš„æŸ¥è©¢æœå°‹çŸ¥è­˜åº«ï¼Œé©åˆéœ€è¦æ¯”è¼ƒæˆ–æ•´åˆå¤šå€‹ä¸»é¡Œçš„å•é¡Œ",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "queries": {
                                "type": "array",
                                "items": {"type": "string"},
                                "description": "å¤šå€‹æœå°‹æŸ¥è©¢çš„åˆ—è¡¨"
                            },
                            "top_k": {
                                "type": "integer",
                                "description": "æ¯å€‹æŸ¥è©¢è¿”å›çš„çµæœæ•¸é‡ï¼Œé è¨­ 3",
                                "default": 3
                            }
                        },
                        "required": ["queries"]
                    }
                }
            }
        ]
        
        self.system_prompt = """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ä¼æ¥­çŸ¥è­˜åº«åŠ©æ‰‹ï¼Œè² è²¬å›ç­”ç”¨æˆ¶é—œæ–¼æ–‡ä»¶å…§å®¹çš„å•é¡Œã€‚

ä½ çš„å·¥ä½œæµç¨‹ï¼š
1. åˆ†æç”¨æˆ¶çš„å•é¡Œï¼Œæ€è€ƒéœ€è¦æœå°‹ä»€éº¼è³‡è¨Š
2. ä½¿ç”¨ rag_search æˆ– rag_search_multiple å·¥å…·æœå°‹çŸ¥è­˜åº«
3. æ ¹æ“šæœå°‹çµæœï¼Œæ•´ç†å‡ºæ¸…æ™°ã€æœ‰æ¢ç†çš„å›ç­”
4. å¦‚æœå•é¡Œæ¶‰åŠå¤šå€‹ä¸»é¡Œï¼ˆå¦‚æ¯”è¼ƒï¼‰ï¼Œä½¿ç”¨ rag_search_multiple ä¸€æ¬¡æœå°‹å¤šå€‹é—œéµå­—

å›ç­”è¦ç¯„ï¼š
- ç”¨ç¹é«”ä¸­æ–‡å›ç­”
- å›ç­”è¦æœ‰çµæ§‹ï¼Œå–„ç”¨æ¨™é¡Œå’Œæ¢åˆ—
- å¿…é ˆåŸºæ–¼æœå°‹åˆ°çš„å…§å®¹å›ç­”ï¼Œä¸è¦ç·¨é€ 
- å¦‚æœæœå°‹çµæœä¸è¶³ä»¥å›ç­”å•é¡Œï¼Œèª å¯¦å‘ŠçŸ¥ç”¨æˆ¶

è«‹å…ˆæ€è€ƒå•é¡Œéœ€è¦ä»€éº¼è³‡è¨Šï¼Œç„¶å¾Œæ±ºå®šæœå°‹ç­–ç•¥ã€‚"""

    def _filtered_search(self, query: str, top_k: int, selected_docs: Optional[List[str]] = None):
        """ğŸ†• æ”¯æ´æ–‡ä»¶ç¯©é¸çš„æœå°‹"""
        from qdrant_client import QdrantClient
        from qdrant_client.models import Filter, FieldCondition, MatchValue
        
        # å¦‚æœæ²’æœ‰ç¯©é¸ï¼Œä½¿ç”¨åŸæœ¬çš„ retriever
        if not selected_docs or len(selected_docs) == 0:
            return self.retriever.search(query, top_k=top_k)
        
        # æœ‰ç¯©é¸ï¼Œç›´æ¥æŸ¥ Qdrant
        try:
            client = QdrantClient(host="localhost", port=6333)
            openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
            
            # ç”ŸæˆæŸ¥è©¢å‘é‡
            embedding_response = openai_client.embeddings.create(
                model="text-embedding-3-small",
                input=query
            )
            query_vector = embedding_response.data[0].embedding
            
            # å»ºç«‹ç¯©é¸æ¢ä»¶
            if len(selected_docs) == 1:
                search_filter = Filter(
                    must=[FieldCondition(key="file_name", match=MatchValue(value=selected_docs[0]))]
                )
            else:
                search_filter = Filter(
                    should=[
                        FieldCondition(key="file_name", match=MatchValue(value=f))
                        for f in selected_docs
                    ]
                )
            
            # åŸ·è¡Œæœå°‹
            results = client.query_points(
                collection_name="rag_knowledge_base",
                query=query_vector,
                query_filter=search_filter,
                limit=top_k,
                with_payload=True
            )
            
            return results.points
            
        except Exception as e:
            print(f"Filtered search error: {e}")
            # å¤±æ•—æ™‚å›é€€åˆ°åŸæœ¬çš„æœå°‹
            return self.retriever.search(query, top_k=top_k)

    def _execute_tool(self, tool_name: str, arguments: dict, selected_docs: Optional[List[str]] = None) -> tuple[str, list]:
        """åŸ·è¡Œå·¥å…·ä¸¦è¿”å›çµæœï¼ŒğŸ†• æ”¯æ´æ–‡ä»¶ç¯©é¸"""
        sources = []
        
        if tool_name == "rag_search":
            query = arguments.get("query", "")
            top_k = arguments.get("top_k", 5)
            
            # ğŸ†• ä½¿ç”¨ç¯©é¸æœå°‹
            results = self._filtered_search(query, top_k, selected_docs)
            
            if not results:
                return "æ²’æœ‰æ‰¾åˆ°ç›¸é—œçµæœ", []
            
            output = []
            for i, hit in enumerate(results, 1):
                payload = hit.payload
                text = payload.get("text", "")[:500]
                source_info = {
                    "file_name": payload.get("file_name", "unknown"),
                    "page_label": payload.get("page_label", "?"),
                    "score": hit.score,
                    "summary": text[:100] + "..."
                }
                sources.append(source_info)
                output.append(f"[çµæœ {i}] ä¾†æº: {source_info['file_name']} (é  {source_info['page_label']})")
                output.append(f"ç›¸é—œåº¦: {hit.score:.3f}")
                output.append(f"å…§å®¹: {text}")
                output.append("")
            
            return "\n".join(output), sources
            
        elif tool_name == "rag_search_multiple":
            queries = arguments.get("queries", [])
            top_k = arguments.get("top_k", 3)
            
            all_output = []
            for query in queries:
                # ğŸ†• ä½¿ç”¨ç¯©é¸æœå°‹
                results = self._filtered_search(query, top_k, selected_docs)
                
                all_output.append(f"=== æœå°‹: {query} ===")
                if not results:
                    all_output.append("æ²’æœ‰æ‰¾åˆ°ç›¸é—œçµæœ")
                else:
                    for i, hit in enumerate(results, 1):
                        payload = hit.payload
                        text = payload.get("text", "")[:400]
                        source_info = {
                            "file_name": payload.get("file_name", "unknown"),
                            "page_label": payload.get("page_label", "?"),
                            "score": hit.score,
                            "summary": text[:100] + "..."
                        }
                        # é¿å…é‡è¤‡ä¾†æº
                        if not any(s["file_name"] == source_info["file_name"] and 
                                   s["page_label"] == source_info["page_label"] for s in sources):
                            sources.append(source_info)
                        all_output.append(f"[{i}] {source_info['file_name']} (é  {source_info['page_label']}): {text[:200]}...")
                all_output.append("")
            
            return "\n".join(all_output), sources
        
        return "æœªçŸ¥å·¥å…·", []

    async def chat_stream(self, user_message: str, selected_docs: Optional[List[str]] = None) -> AsyncGenerator[AgentEvent, None]:
        """ä¸²æµå¼å°è©±ï¼Œè¿”å› Agent äº‹ä»¶ï¼ŒğŸ†• æ”¯æ´æ–‡ä»¶ç¯©é¸"""
        
        # ğŸ†• å¦‚æœæœ‰ç¯©é¸ï¼Œåœ¨ system prompt ä¸­æç¤º
        system_prompt = self.system_prompt
        if selected_docs and len(selected_docs) > 0:
            docs_list = ", ".join(selected_docs)
            system_prompt += f"\n\næ³¨æ„ï¼šç”¨æˆ¶é¸æ“‡äº†ä»¥ä¸‹æ–‡ä»¶é€²è¡Œæœå°‹ï¼š{docs_list}ã€‚è«‹åªåœ¨é€™äº›æ–‡ä»¶ä¸­æœå°‹ã€‚"
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_message}
        ]
        
        all_sources = []
        max_iterations = 5  # é˜²æ­¢ç„¡é™è¿´åœˆ
        
        for iteration in range(max_iterations):
            try:
                # å‘¼å« OpenAI
                response = self.client.chat.completions.create(
                    model="gpt-4o",
                    messages=messages,
                    tools=self.tools,
                    tool_choice="auto"
                )
                
                assistant_message = response.choices[0].message
                
                # æª¢æŸ¥æ˜¯å¦æœ‰å·¥å…·å‘¼å«
                if assistant_message.tool_calls:
                    # æœ‰å·¥å…·å‘¼å«
                    messages.append(assistant_message)
                    
                    for tool_call in assistant_message.tool_calls:
                        tool_name = tool_call.function.name
                        arguments = json.loads(tool_call.function.arguments)
                        
                        # ç™¼é€ thinking äº‹ä»¶
                        if tool_name == "rag_search":
                            thinking = f"æœå°‹çŸ¥è­˜åº«ï¼šã€Œ{arguments.get('query', '')}ã€"
                        elif tool_name == "rag_search_multiple":
                            queries = arguments.get('queries', [])
                            thinking = f"å¤šé‡æœå°‹ï¼š{', '.join(queries)}"
                        else:
                            thinking = f"åŸ·è¡Œå·¥å…·ï¼š{tool_name}"
                        
                        yield AgentEvent(
                            type=EventType.THINKING,
                            content=thinking
                        )
                        
                        # ç™¼é€å·¥å…·å‘¼å«äº‹ä»¶
                        yield AgentEvent(
                            type=EventType.TOOL_CALL,
                            content=tool_name,
                            data={"arguments": arguments}
                        )
                        
                        # ğŸ†• åŸ·è¡Œå·¥å…·ï¼ˆå‚³å…¥ selected_docsï¼‰
                        result, sources = self._execute_tool(tool_name, arguments, selected_docs)
                        all_sources.extend(sources)
                        
                        # ç™¼é€å·¥å…·çµæœäº‹ä»¶
                        result_preview = result[:200] + "..." if len(result) > 200 else result
                        yield AgentEvent(
                            type=EventType.TOOL_RESULT,
                            content=f"æ‰¾åˆ° {len(sources)} å€‹ç›¸é—œç‰‡æ®µ",
                            data={"preview": result_preview}
                        )
                        
                        # åŠ å…¥å·¥å…·çµæœåˆ°å°è©±
                        messages.append({
                            "role": "tool",
                            "tool_call_id": tool_call.id,
                            "content": result
                        })
                        
                        # å°å»¶é²è®“å‰ç«¯æœ‰æ™‚é–“é¡¯ç¤º
                        await asyncio.sleep(0.1)
                
                else:
                    # æ²’æœ‰å·¥å…·å‘¼å«ï¼Œè¿”å›æœ€çµ‚å›ç­”
                    final_answer = assistant_message.content
                    
                    # ä¸²æµè¼¸å‡ºå›ç­”
                    yield AgentEvent(
                        type=EventType.ANSWER,
                        content=final_answer
                    )
                    
                    # ç™¼é€ä¾†æºï¼ˆå»é‡ä¸¦æ’åºï¼‰
                    unique_sources = []
                    seen = set()
                    for s in all_sources:
                        key = (s["file_name"], s["page_label"])
                        if key not in seen:
                            seen.add(key)
                            unique_sources.append(s)
                    
                    # æŒ‰ç›¸é—œåº¦æ’åº
                    unique_sources.sort(key=lambda x: x.get("score", 0), reverse=True)
                    
                    if unique_sources:
                        yield AgentEvent(
                            type=EventType.SOURCE,
                            content=f"{len(unique_sources)} å€‹åƒè€ƒä¾†æº",
                            data={"sources": unique_sources[:5]}
                        )
                    
                    # å®Œæˆ
                    yield AgentEvent(type=EventType.DONE, content="")
                    return
                    
            except Exception as e:
                yield AgentEvent(
                    type=EventType.ERROR,
                    content=f"è™•ç†éŒ¯èª¤: {str(e)}"
                )
                return
        
        # é”åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•¸
        yield AgentEvent(
            type=EventType.ERROR,
            content="è™•ç†è¶…æ™‚ï¼Œè«‹ç°¡åŒ–å•é¡Œå¾Œé‡è©¦"
        )