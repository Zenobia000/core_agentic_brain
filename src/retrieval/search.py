import os
import logging
from typing import List
from qdrant_client import QdrantClient
from llama_index.embeddings.openai import OpenAIEmbedding

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# [é—œéµä¸€è‡´æ€§ 1] å¿…é ˆè·Ÿ indexer.py çš„åç¨±ä¸€æ¨¡ä¸€æ¨£
COLLECTION_NAME = "rag_knowledge_base"

class HybridRetriever:
    def __init__(self):
        self.qdrant_url = os.getenv("QDRANT_URL", "http://localhost:6333")
        self.api_key = os.getenv("OPENAI_API_KEY")
        
        # 1. åˆå§‹åŒ– Qdrant å®¢æˆ¶ç«¯
        self.client = QdrantClient(url=self.qdrant_url)
        
        # [é—œéµä¸€è‡´æ€§ 2] å¿…é ˆè·Ÿ indexer.py ä½¿ç”¨åŒä¸€é¡†æ¨¡å‹
        # å¦‚æœå¯«å…¥ç”¨ text-embedding-3-smallï¼Œè®€å–ä¹Ÿè¦ç”¨é€™é¡†ï¼Œä¸ç„¶å‘é‡ç©ºé–“æœƒå°ä¸æº–
        self.embed_model = OpenAIEmbedding(
            model="text-embedding-3-small",
            api_key=self.api_key
        )

    def search(self, query_text: str, top_k: int = 5):
        """
        åŸ·è¡Œå‘é‡æœå°‹
        """
        logger.info(f"ğŸ” æœå°‹: {query_text}")

        try:
            # 1. å°‡ä½¿ç”¨è€…çš„å•é¡Œè½‰æˆå‘é‡
            query_vector = self.embed_model.get_query_embedding(query_text)

            # 2. å» Qdrant æœå°‹
            search_result = self.client.search(
                collection_name=COLLECTION_NAME,
                query_vector=query_vector,
                limit=top_k,
                with_payload=True # è¨˜å¾—æŠŠåŸæœ¬çš„æ–‡å­— (payload) æŠ“å›ä¾†
            )

            if not search_result:
                logger.warning("âš ï¸ æ‰¾ä¸åˆ°ç›¸é—œè³‡æ–™")
                return []

            logger.info(f"âœ… æ‰¾åˆ° {len(search_result)} ç­†ç›¸é—œè³‡æ–™")
            return search_result

        except Exception as e:
            logger.error(f"âŒ æœå°‹å¤±æ•—: {e}")
            return []