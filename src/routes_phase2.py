"""
Phase 2 å¾Œç«¯è·¯ç”±æ“´å±• - ä¿®å¾©ç‰ˆ
Collection: rag_knowledge_base
Payload: text, file_name, page_label
"""

from fastapi import APIRouter, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse
from typing import List, Optional
from pydantic import BaseModel
import os
import time
from datetime import datetime

router = APIRouter()

# ========== é…ç½® ==========
COLLECTION_NAME = "rag_knowledge_base"
PDF_DIR = "data/raw"

# ============================================
# 1ï¸âƒ£ å¤š PDF é¸æ“‡å™¨ API
# ============================================

@router.get("/documents")
async def list_documents():
    """åˆ—å‡ºæ‰€æœ‰å·²ä¸Šå‚³çš„ PDF æ–‡ä»¶"""
    from qdrant_client import QdrantClient
    
    documents = []
    
    try:
        client = QdrantClient(host="localhost", port=6333)
        has_qdrant = True
    except:
        has_qdrant = False
    
    if os.path.exists(PDF_DIR):
        for filename in os.listdir(PDF_DIR):
            if filename.lower().endswith('.pdf'):
                filepath = os.path.join(PDF_DIR, filename)
                
                indexed = False
                vector_count = 0
                
                if has_qdrant:
                    try:
                        # ä½¿ç”¨æ­£ç¢ºçš„ payload å­—æ®µå file_name
                        results, _ = client.scroll(
                            collection_name=COLLECTION_NAME,
                            scroll_filter={
                                "must": [
                                    {"key": "file_name", "match": {"value": filename}}
                                ]
                            },
                            limit=1,
                            with_payload=False,
                            with_vectors=False
                        )
                        indexed = len(results) > 0
                        
                        if indexed:
                            all_points, _ = client.scroll(
                                collection_name=COLLECTION_NAME,
                                scroll_filter={
                                    "must": [
                                        {"key": "file_name", "match": {"value": filename}}
                                    ]
                                },
                                limit=10000,
                                with_payload=False,
                                with_vectors=False
                            )
                            vector_count = len(all_points)
                    except Exception as e:
                        print(f"Error checking index for {filename}: {e}")
                
                documents.append({
                    "name": filename,
                    "path": f"/files/{filename}",
                    "size": os.path.getsize(filepath),
                    "indexed": indexed,
                    "vector_count": vector_count,
                    "modified": datetime.fromtimestamp(os.path.getmtime(filepath)).isoformat()
                })
    
    documents.sort(key=lambda x: x["modified"], reverse=True)
    
    return {"documents": documents, "total": len(documents)}


@router.delete("/documents/{filename}")
async def delete_document(filename: str):
    """åˆªé™¤ PDF æ–‡ä»¶åŠå…¶å‘é‡ç´¢å¼•"""
    from qdrant_client import QdrantClient
    from qdrant_client.models import Filter, FieldCondition, MatchValue
    
    filepath = f"{PDF_DIR}/{filename}"
    file_deleted = False
    if os.path.exists(filepath):
        os.remove(filepath)
        file_deleted = True
    
    vectors_deleted = 0
    try:
        client = QdrantClient(host="localhost", port=6333)
        
        points, _ = client.scroll(
            collection_name=COLLECTION_NAME,
            scroll_filter=Filter(
                must=[FieldCondition(key="file_name", match=MatchValue(value=filename))]
            ),
            limit=10000,
            with_payload=False
        )
        vectors_deleted = len(points)
        
        if vectors_deleted > 0:
            point_ids = [p.id for p in points]
            client.delete(
                collection_name=COLLECTION_NAME,
                points_selector=point_ids
            )
    except Exception as e:
        print(f"Error deleting vectors: {e}")
    
    return {
        "message": f"å·²åˆªé™¤ {filename}",
        "file_deleted": file_deleted,
        "vectors_deleted": vectors_deleted
    }


class FilteredSearchRequest(BaseModel):
    query: str
    filenames: Optional[List[str]] = None
    top_k: int = 5


@router.post("/search/filtered")
async def filtered_search(request: FilteredSearchRequest):
    """åœ¨æŒ‡å®šçš„æ–‡ä»¶ä¸­æœå°‹"""
    from qdrant_client import QdrantClient
    from qdrant_client.models import Filter, FieldCondition, MatchValue
    from openai import OpenAI
    
    client = QdrantClient(host="localhost", port=6333)
    openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    embedding_response = openai_client.embeddings.create(
        model="text-embedding-3-small",
        input=request.query
    )
    query_vector = embedding_response.data[0].embedding
    
    search_filter = None
    if request.filenames and len(request.filenames) > 0:
        if len(request.filenames) == 1:
            search_filter = Filter(
                must=[FieldCondition(key="file_name", match=MatchValue(value=request.filenames[0]))]
            )
        else:
            search_filter = Filter(
                should=[
                    FieldCondition(key="file_name", match=MatchValue(value=f))
                    for f in request.filenames
                ]
            )
    
    results = client.query_points(
        collection_name=COLLECTION_NAME,
        query=query_vector,
        query_filter=search_filter,
        limit=request.top_k,
        with_payload=True
    )
    
    return {
        "results": [
            {
                "content": point.payload.get("text", ""),
                "source": point.payload.get("file_name", ""),
                "page": point.payload.get("page_label", "1"),
                "score": point.score
            }
            for point in results.points
        ],
        "query": request.query,
        "filtered_by": request.filenames
    }


# ============================================
# 2ï¸âƒ£ Deep Research API
# ============================================

research_tasks = {}


class ResearchRequest(BaseModel):
    topic: str
    documents: Optional[List[str]] = None


@router.post("/research/start")
async def start_research(request: ResearchRequest, background_tasks: BackgroundTasks):
    """å•Ÿå‹•æ·±åº¦ç ”ç©¶ä»»å‹™"""
    task_id = f"research_{int(time.time() * 1000)}"
    
    research_tasks[task_id] = {
        "status": "running",
        "progress": 0,
        "steps": [],
        "report": None,
        "error": None,
        "created_at": datetime.now().isoformat()
    }
    
    background_tasks.add_task(
        run_deep_research,
        task_id,
        request.topic,
        request.documents
    )
    
    return {"task_id": task_id, "status": "started"}


async def run_deep_research(task_id: str, topic: str, documents: Optional[List[str]]):
    """åŸ·è¡Œæ·±åº¦ç ”ç©¶"""
    from openai import OpenAI
    
    task = research_tasks[task_id]
    openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    try:
        task["steps"].append({"step": "ðŸ” åˆ†æžç ”ç©¶ä¸»é¡Œ", "status": "running"})
        task["progress"] = 5
        
        sub_questions = await generate_sub_questions(openai_client, topic)
        
        task["steps"][-1]["status"] = "done"
        task["steps"][-1]["result"] = f"ç”Ÿæˆ {len(sub_questions)} å€‹å­å•é¡Œ"
        task["progress"] = 15
        
        all_findings = []
        all_sources = []
        
        for i, question in enumerate(sub_questions):
            task["steps"].append({
                "step": f"ðŸ“š ç ”ç©¶: {question[:40]}...",
                "status": "running"
            })
            
            search_results = await search_for_research(question, documents)
            
            if search_results:
                all_sources.extend(search_results)
                answer = await generate_section_answer(openai_client, question, search_results)
                
                all_findings.append({
                    "question": question,
                    "answer": answer,
                    "sources": search_results
                })
            
            task["steps"][-1]["status"] = "done"
            task["steps"][-1]["result"] = f"æ‰¾åˆ° {len(search_results)} å€‹ç›¸é—œæ®µè½"
            task["progress"] = 15 + (i + 1) * (65 / len(sub_questions))
        
        task["steps"].append({"step": "ðŸ“ æ’°å¯«ç ”ç©¶å ±å‘Š", "status": "running"})
        task["progress"] = 85
        
        report = await generate_final_report(openai_client, topic, all_findings)
        
        unique_sources = {}
        for s in all_sources:
            key = f"{s['source']}_p{s['page']}"
            if key not in unique_sources:
                unique_sources[key] = s
        
        task["steps"][-1]["status"] = "done"
        task["progress"] = 100
        task["status"] = "completed"
        task["report"] = {
            "title": f"ç ”ç©¶å ±å‘Šï¼š{topic}",
            "content": report,
            "sources": list(unique_sources.values()),
            "findings_count": len(all_findings),
            "generated_at": datetime.now().isoformat()
        }
        
    except Exception as e:
        task["status"] = "failed"
        task["error"] = str(e)
        task["steps"].append({"step": "âŒ ç™¼ç”ŸéŒ¯èª¤", "status": "failed", "result": str(e)})


async def generate_sub_questions(client, topic: str) -> List[str]:
    """ç”Ÿæˆå­å•é¡Œ"""
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": """ä½ æ˜¯ä¸€å€‹ç ”ç©¶åŠ©æ‰‹ã€‚æ ¹æ“šçµ¦å®šçš„ä¸»é¡Œï¼Œç”Ÿæˆ 3-5 å€‹æ·±å…¥ä¸”å…·é«”çš„ç ”ç©¶å­å•é¡Œã€‚
é€™äº›å•é¡Œæ‡‰è©²æ¶µè“‹ä¸»é¡Œçš„ä¸åŒé¢å‘ã€‚åªè¼¸å‡ºå•é¡Œåˆ—è¡¨ï¼Œæ¯è¡Œä¸€å€‹å•é¡Œï¼Œä¸è¦ç·¨è™Ÿã€‚"""
            },
            {"role": "user", "content": f"ç ”ç©¶ä¸»é¡Œï¼š{topic}"}
        ],
        temperature=0.7
    )
    
    questions = response.choices[0].message.content.strip().split('\n')
    return [q.strip().lstrip('0123456789.-â€¢) ') for q in questions if q.strip() and len(q.strip()) > 5]


async def search_for_research(query: str, documents: Optional[List[str]]) -> List[dict]:
    """åŸ·è¡Œå‘é‡æœå°‹"""
    from qdrant_client import QdrantClient
    from qdrant_client.models import Filter, FieldCondition, MatchValue
    from openai import OpenAI
    
    client = QdrantClient(host="localhost", port=6333)
    openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    
    embedding_response = openai_client.embeddings.create(
        model="text-embedding-3-small",
        input=query
    )
    query_vector = embedding_response.data[0].embedding
    
    search_filter = None
    if documents and len(documents) > 0:
        search_filter = Filter(
            should=[
                FieldCondition(key="file_name", match=MatchValue(value=f))
                for f in documents
            ]
        )
    
    results = client.query_points(
        collection_name=COLLECTION_NAME,
        query=query_vector,
        query_filter=search_filter,
        limit=5,
        with_payload=True
    )
    
    return [
        {
            "content": point.payload.get("text", ""),
            "source": point.payload.get("file_name", ""),
            "page": point.payload.get("page_label", "1"),
            "score": point.score
        }
        for point in results.points
    ]


async def generate_section_answer(client, question: str, sources: List[dict]) -> str:
    """ç”Ÿæˆå–®å€‹å•é¡Œçš„ç­”æ¡ˆ"""
    context = "\n\n".join([
        f"[ä¾†æº: {s['source']}, é ç¢¼: {s['page']}]\n{s['content']}"
        for s in sources
    ])
    
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": "æ ¹æ“šæä¾›çš„è³‡æ–™ä¾†æºï¼Œå›žç­”å•é¡Œã€‚ä¿æŒå®¢è§€ã€æº–ç¢ºï¼Œä¸¦æ¨™è¨»é—œéµè³‡è¨Šçš„ä¾†æºã€‚"
            },
            {"role": "user", "content": f"å•é¡Œï¼š{question}\n\nåƒè€ƒè³‡æ–™ï¼š\n{context}"}
        ],
        temperature=0.3
    )
    
    return response.choices[0].message.content


async def generate_final_report(client, topic: str, findings: List[dict]) -> str:
    """ç”Ÿæˆæœ€çµ‚å ±å‘Š"""
    findings_text = "\n\n---\n\n".join([
        f"### {f['question']}\n\n{f['answer']}"
        for f in findings
    ])
    
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "system",
                "content": """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ç ”ç©¶å ±å‘Šæ’°å¯«è€…ã€‚æ ¹æ“šæä¾›çš„ç ”ç©¶ç™¼ç¾ï¼Œç”Ÿæˆä¸€ä»½çµæ§‹å®Œæ•´çš„ç ”ç©¶å ±å‘Šã€‚

å ±å‘Šæ ¼å¼ï¼ˆä½¿ç”¨ Markdownï¼‰ï¼š
# æ¨™é¡Œ

## ðŸ“‹ åŸ·è¡Œæ‘˜è¦
ç°¡æ½”ç¸½çµä¸»è¦ç™¼ç¾ï¼ˆ3-5 å¥ï¼‰

## ðŸ” ä¸»è¦ç™¼ç¾
åˆ—å‡º 3-5 å€‹é—œéµç™¼ç¾

## ðŸ“– è©³ç´°åˆ†æž
æ•´åˆæ‰€æœ‰ç ”ç©¶ç™¼ç¾ï¼Œå½¢æˆé€£è²«çš„åˆ†æž

## ðŸ’¡ çµè«–èˆ‡å»ºè­°
ç¸½çµä¸¦æå‡ºå»ºè­°"""
            },
            {"role": "user", "content": f"ç ”ç©¶ä¸»é¡Œï¼š{topic}\n\nç ”ç©¶ç™¼ç¾ï¼š\n{findings_text}"}
        ],
        temperature=0.4
    )
    
    return response.choices[0].message.content


@router.get("/research/{task_id}")
async def get_research_status(task_id: str):
    """å–å¾—ç ”ç©¶ä»»å‹™ç‹€æ…‹"""
    if task_id not in research_tasks:
        raise HTTPException(status_code=404, detail="Task not found")
    return research_tasks[task_id]


@router.get("/research")
async def list_research_tasks():
    """åˆ—å‡ºæ‰€æœ‰ç ”ç©¶ä»»å‹™"""
    return {
        "tasks": [
            {
                "task_id": tid,
                "status": t["status"],
                "progress": t["progress"],
                "created_at": t.get("created_at"),
                "title": t.get("report", {}).get("title", "é€²è¡Œä¸­...")
            }
            for tid, t in research_tasks.items()
        ]
    }


# ============================================
# 3ï¸âƒ£ Qdrant ç®¡ç† API
# ============================================

@router.get("/qdrant/collections")
async def list_collections():
    """åˆ—å‡ºæ‰€æœ‰ Qdrant collections"""
    from qdrant_client import QdrantClient
    
    client = QdrantClient(host="localhost", port=6333)
    
    try:
        collections = client.get_collections().collections
        result = []
        
        for c in collections:
            info = client.get_collection(c.name)
            result.append({
                "name": c.name,
                "vectors_count": info.vectors_count,
                "points_count": info.points_count,
                "status": str(info.status)
            })
        
        return {"collections": result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/qdrant/collection/{name}")
async def get_collection_info(name: str):
    """å–å¾— collection è©³ç´°è³‡è¨Š"""
    from qdrant_client import QdrantClient
    
    client = QdrantClient(host="localhost", port=6333)
    
    try:
        info = client.get_collection(name)
        
        points, _ = client.scroll(
            collection_name=name,
            limit=10000,
            with_payload=["file_name"],
            with_vectors=False
        )
        
        doc_stats = {}
        for p in points:
            # ä½¿ç”¨æ­£ç¢ºçš„å­—æ®µå file_name
            source = p.payload.get("file_name", "unknown")
            doc_stats[source] = doc_stats.get(source, 0) + 1
        
        return {
            "name": name,
            "vectors_count": info.vectors_count,
            "points_count": info.points_count,
            "status": str(info.status),
            "config": {
                "size": info.config.params.vectors.size if hasattr(info.config.params.vectors, 'size') else None,
                "distance": str(info.config.params.vectors.distance) if hasattr(info.config.params.vectors, 'distance') else None
            },
            "documents": [
                {"name": k, "vectors": v}
                for k, v in sorted(doc_stats.items(), key=lambda x: -x[1])
            ]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/qdrant/collection/{name}/points")
async def browse_points(name: str, limit: int = 20, offset: Optional[str] = None):
    """ç€è¦½ collection ä¸­çš„ points"""
    from qdrant_client import QdrantClient
    
    client = QdrantClient(host="localhost", port=6333)
    
    try:
        points, next_offset = client.scroll(
            collection_name=name,
            limit=limit,
            offset=offset,
            with_payload=True,
            with_vectors=False
        )
        
        return {
            "points": [
                {
                    "id": str(p.id),
                    "payload": {
                        # ä½¿ç”¨æ­£ç¢ºçš„å­—æ®µå
                        "source": p.payload.get("file_name", ""),
                        "page": p.payload.get("page_label", ""),
                        "content": p.payload.get("text", "")[:300] + "..." if len(p.payload.get("text", "")) > 300 else p.payload.get("text", "")
                    }
                }
                for p in points
            ],
            "next_offset": str(next_offset) if next_offset else None,
            "count": len(points)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.delete("/qdrant/collection/{name}")
async def delete_collection(name: str):
    """åˆªé™¤ collection"""
    from qdrant_client import QdrantClient
    
    client = QdrantClient(host="localhost", port=6333)
    
    try:
        client.delete_collection(name)
        return {"message": f"Collection '{name}' deleted successfully"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
