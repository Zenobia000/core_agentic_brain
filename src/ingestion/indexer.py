import os
import logging
from typing import List
from qdrant_client import QdrantClient
from qdrant_client.http import models
from llama_index.core.schema import BaseNode
from llama_index.embeddings.openai import OpenAIEmbedding

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# è¨­å®š Collection åç¨±
COLLECTION_NAME = "rag_knowledge_base"

async def index_nodes(nodes: List[BaseNode]):
    """
    å°‡è™•ç†å¥½çš„ç¯€é» (å« NQ1D å•é¡Œ) å¯«å…¥ Qdrant å‘é‡è³‡æ–™åº«ã€‚
    åŒ…å«ï¼š
    1. ç”Ÿæˆå‘é‡ (Content Vector)
    2. å»ºç«‹ Collection (å¦‚æœä¸å­˜åœ¨)
    3. æ‰¹æ¬¡å¯«å…¥ (Upsert)
    """
    qdrant_url = os.getenv("QDRANT_URL", "http://localhost:6333")
    api_key = os.getenv("OPENAI_API_KEY")

    if not nodes:
        logger.warning("âš ï¸ æ²’æœ‰ç¯€é»éœ€è¦ç´¢å¼•")
        return 0

    # 1. åˆå§‹åŒ–å®¢æˆ¶ç«¯
    client = QdrantClient(url=qdrant_url)
    
    # åˆå§‹åŒ– Embedding æ¨¡å‹ (ç”¨ä¾†æŠŠæ–‡å­—è®Šæˆå‘é‡)
    # é€™è£¡æˆ‘å€‘ä½¿ç”¨ OpenAI text-embedding-3-small (CP å€¼æœ€é«˜)
    embed_model = OpenAIEmbedding(
        model="text_embedding_3_small", 
        api_key=api_key
    )

    # 2. æª¢æŸ¥ä¸¦å»ºç«‹ Collection
    if not client.collection_exists(collection_name=COLLECTION_NAME):
        logger.info(f"ğŸ†• Collection ä¸å­˜åœ¨ï¼Œæ­£åœ¨å»ºç«‹: {COLLECTION_NAME}...")
        client.create_collection(
            collection_name=COLLECTION_NAME,
            vectors_config=models.VectorParams(
                size=1536,  # text-embedding-3-small çš„ç¶­åº¦
                distance=models.Distance.COSINE
            )
        )
    else:
        logger.info(f"âœ… å‘é‡é›†åˆå·²å­˜åœ¨: {COLLECTION_NAME}")

    # 3. ç”Ÿæˆå‘é‡ (Batch Embedding)
    logger.info(f"âš¡ æ­£åœ¨ç‚º {len(nodes)} ç­†è³‡æ–™ç”Ÿæˆå‘é‡...")
    
    points = []
    for node in nodes:
        # æº–å‚™è¦å‘é‡åŒ–çš„æ–‡å­—
        # ç­–ç•¥ï¼šæˆ‘å€‘ä¸»è¦å°ã€Œå…§æ–‡ã€åšå‘é‡åŒ–ã€‚
        # (é€²éšç­–ç•¥ï¼šä¹Ÿå¯ä»¥æŠŠç”Ÿæˆçš„ NQ1D å•é¡ŒåŠ é€²ä¾†ä¸€èµ·ç®—ï¼Œé€™è£¡æˆ‘å€‘å…ˆå–®ç´”ä¸€é»ç®—å…§æ–‡)
        text_to_embed = node.text 
        
        try:
            # å‘¼å« OpenAI ç”Ÿæˆå‘é‡
            vector = embed_model.get_text_embedding(text_to_embed)
            
            # æ•´ç† Payload (è¦å­˜é€²è³‡æ–™åº«çš„æ¬„ä½)
            # é€™è£¡æˆ‘å€‘æŠŠç”Ÿæˆçš„ "questions" ä¹Ÿå­˜é€²å»ï¼Œæ–¹ä¾¿ä¹‹å¾Œåšé—œéµå­—æœå°‹
            payload = {
                "text": node.text,
                "file_name": node.metadata.get("file_name", "unknown"),
                "page_label": node.metadata.get("page_label", "unknown"),
                "questions": node.metadata.get("questions", []), # NQ1D å•é¡Œ
                "processed_by": node.metadata.get("processed_by", "unknown")
            }

            # å»ºç«‹ Qdrant Point
            point = models.PointStruct(
                id=node.node_id, # ä½¿ç”¨ LlamaIndex ç”Ÿæˆçš„ UUID
                vector=vector,
                payload=payload
            )
            points.append(point)
            
        except Exception as e:
            logger.error(f"âŒ å‘é‡åŒ–å¤±æ•— (Node ID: {node.node_id}): {e}")

    # 4. å¯«å…¥è³‡æ–™åº« (Upsert)
    if points:
        client.upsert(
            collection_name=COLLECTION_NAME,
            points=points
        )
        logger.info(f"âœ… æˆåŠŸå¯«å…¥ {len(points)} ç­†è³‡æ–™åˆ° Qdrantï¼")
        return len(points)
    else:
        logger.warning("âš ï¸ æ²’æœ‰è³‡æ–™è¢«å¯«å…¥")
        return 0