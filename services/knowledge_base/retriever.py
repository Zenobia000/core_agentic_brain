"""
Retriever - ä½¿ç”¨ Cohere Embedding æŸ¥è©¢ Qdrant
æ”¯æ´ Cohere å’Œ OpenAI é›™ provider
"""

import os
import logging
from typing import List, Dict, Any, Optional
from pathlib import Path

from dotenv import load_dotenv

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
_project_root = Path(__file__).resolve().parent.parent.parent
_env_path = _project_root / ".env"
load_dotenv(_env_path)

logger = logging.getLogger(__name__)

# å…¨åŸŸå¯¦ä¾‹
_retriever_instance = None


class Retriever:
    """
    å‘é‡æª¢ç´¢å™¨ - æ”¯æ´ Cohere å’Œ OpenAI embedding
    
    é‡è¦ï¼šCohere æŸ¥è©¢æ™‚å¿…é ˆä½¿ç”¨ input_type="search_query"
    """
    
    def __init__(
        self,
        collection_name: str = "rag_knowledge_base",
        qdrant_url: str = "http://localhost:6333"
    ):
        self.collection_name = collection_name
        self.qdrant_url = qdrant_url
        
        # API clients
        self.cohere_client = None
        self.openai_client = None
        self.qdrant_client = None
        
        # Embedding è¨­å®š
        self.embed_provider = None
        self.embed_model = None
        
        self._initialize()
    
    def _initialize(self):
        """åˆå§‹åŒ– clients"""
        # ç¢ºä¿ç’°å¢ƒè®Šæ•¸å·²è¼‰å…¥
        load_dotenv(_env_path, override=True)
        
        cohere_key = os.getenv("COHERE_API_KEY")
        openai_key = os.getenv("OPENAI_API_KEY")
        
        # å„ªå…ˆä½¿ç”¨ Cohere
        if cohere_key:
            try:
                import cohere
                self.cohere_client = cohere.Client(api_key=cohere_key)
                self.embed_provider = "cohere"
                self.embed_model = os.getenv("COHERE_EMBED_MODEL", "embed-multilingual-v3.0")
                logger.info(f"âœ… [Retriever] ä½¿ç”¨ Cohere embedding: {self.embed_model}")
            except ImportError:
                logger.warning("âš ï¸ [Retriever] cohere å¥—ä»¶æœªå®‰è£")
            except Exception as e:
                logger.error(f"âŒ [Retriever] Cohere åˆå§‹åŒ–å¤±æ•—: {e}")
        
        # å‚™ç”¨ï¼šOpenAI
        if not self.cohere_client and openai_key:
            try:
                from openai import OpenAI
                self.openai_client = OpenAI(api_key=openai_key)
                self.embed_provider = "openai"
                self.embed_model = "text-embedding-3-small"
                logger.info(f"âœ… [Retriever] ä½¿ç”¨ OpenAI embedding: {self.embed_model}")
            except ImportError:
                logger.warning("âš ï¸ [Retriever] openai å¥—ä»¶æœªå®‰è£")
            except Exception as e:
                logger.error(f"âŒ [Retriever] OpenAI åˆå§‹åŒ–å¤±æ•—: {e}")
        
        if not self.cohere_client and not self.openai_client:
            logger.error("âŒ [Retriever] æ²’æœ‰å¯ç”¨çš„ embedding providerï¼")
            raise ValueError("éœ€è¦è¨­å®š COHERE_API_KEY æˆ– OPENAI_API_KEY")
        
        # åˆå§‹åŒ– Qdrant
        self._init_qdrant()
    
    def _init_qdrant(self):
        """åˆå§‹åŒ– Qdrant client"""
        try:
            from qdrant_client import QdrantClient
            self.qdrant_client = QdrantClient(url=self.qdrant_url)
            logger.info(f"âœ… [Retriever] Qdrant é€£æ¥æˆåŠŸ: {self.qdrant_url}")
        except Exception as e:
            logger.error(f"âŒ [Retriever] Qdrant åˆå§‹åŒ–å¤±æ•—: {e}")
            raise
    
    def get_query_embedding(self, query: str) -> List[float]:
        """
        å–å¾—æŸ¥è©¢çš„ embedding å‘é‡
        
        é‡è¦ï¼šCohere å¿…é ˆä½¿ç”¨ input_type="search_query"
        """
        if self.cohere_client:
            return self._get_cohere_embedding(query)
        else:
            return self._get_openai_embedding(query)
    
    def _get_cohere_embedding(self, text: str) -> List[float]:
        """ä½¿ç”¨ Cohere å–å¾—æŸ¥è©¢ embedding"""
        try:
            response = self.cohere_client.embed(
                texts=[text],
                model=self.embed_model,
                input_type="search_query"  # é‡è¦ï¼æŸ¥è©¢æ™‚ä½¿ç”¨ search_query
            )
            return response.embeddings[0]
        except Exception as e:
            logger.error(f"âŒ [Retriever] Cohere embedding å¤±æ•—: {e}")
            raise
    
    def _get_openai_embedding(self, text: str) -> List[float]:
        """ä½¿ç”¨ OpenAI å–å¾— embedding"""
        try:
            response = self.openai_client.embeddings.create(
                model=self.embed_model,
                input=text
            )
            return response.data[0].embedding
        except Exception as e:
            logger.error(f"âŒ [Retriever] OpenAI embedding å¤±æ•—: {e}")
            raise
    
    def search(
        self,
        query: str,
        top_k: int = 5,
        filters: Optional[Dict[str, Any]] = None
    ) -> List[Dict[str, Any]]:
        """
        èªæ„æœå°‹
        
        Args:
            query: æœå°‹æŸ¥è©¢
            top_k: è¿”å›çµæœæ•¸é‡
            filters: éæ¿¾æ¢ä»¶ï¼Œå¦‚ {"file_name": ["doc1.pdf", "doc2.pdf"]}
            
        Returns:
            æœå°‹çµæœåˆ—è¡¨
        """
        logger.info(f"ğŸ” [Retriever] ====== é–‹å§‹æœå°‹ ======")
        logger.info(f"ğŸ” [Retriever] Query: {query[:50]}...")
        logger.info(f"ğŸ” [Retriever] Top-K: {top_k}")
        logger.info(f"ğŸ” [Retriever] Filters: {filters}")
        
        from qdrant_client.models import Filter, FieldCondition, MatchValue
        
        try:
            # å–å¾—æŸ¥è©¢å‘é‡
            query_vector = self.get_query_embedding(query)
            logger.info(f"âœ… [Retriever] Query embedding å®Œæˆ (dim: {len(query_vector)})")
            
            # å»ºæ§‹éæ¿¾æ¢ä»¶
            search_filter = None
            if filters:
                conditions = []
                for key, value in filters.items():
                    if isinstance(value, list):
                        # å¤šå€¼ç¯©é¸ (OR)
                        conditions.append(Filter(should=[
                            FieldCondition(key=key, match=MatchValue(value=v))
                            for v in value
                        ]))
                    else:
                        conditions.append(
                            FieldCondition(key=key, match=MatchValue(value=value))
                        )
                if conditions:
                    search_filter = Filter(must=conditions)
                    logger.info(f"ğŸ“‹ [Retriever] éæ¿¾æ¢ä»¶å·²å»ºæ§‹: {len(conditions)} å€‹æ¢ä»¶")
            
            # åŸ·è¡Œæœå°‹
            results = self.qdrant_client.query_points(
                collection_name=self.collection_name,
                query=query_vector,
                query_filter=search_filter,
                limit=top_k,
                with_payload=True
            )
            
            logger.info(f"âœ… [Retriever] æ‰¾åˆ° {len(results.points)} å€‹çµæœ")
            
            # è©³ç´°è¨˜éŒ„çµæœ
            for i, point in enumerate(results.points):
                file_name = point.payload.get("file_name", "unknown")
                text_preview = point.payload.get("text", "")[:50]
                logger.info(f"  [{i+1}] score={point.score:.4f}, file={file_name}")
                logger.debug(f"      text: {text_preview}...")
            
            # è½‰æ›ç‚ºæ¨™æº–æ ¼å¼
            return [
                {
                    "text": p.payload.get("text", ""),
                    "file_name": p.payload.get("file_name", "unknown"),
                    "page_label": p.payload.get("page_label", "?"),
                    "score": p.score,
                    "metadata": p.payload
                }
                for p in results.points
            ]
            
        except Exception as e:
            logger.error(f"âŒ [Retriever] æœå°‹å¤±æ•—: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return []
    
    def search_multiple(
        self,
        queries: List[str],
        top_k: int = 3,
        filters: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        å¤šæŸ¥è©¢æœå°‹
        
        Args:
            queries: å¤šå€‹æŸ¥è©¢
            top_k: æ¯å€‹æŸ¥è©¢è¿”å›çš„çµæœæ•¸é‡
            filters: éæ¿¾æ¢ä»¶
            
        Returns:
            åˆä½µçš„æœå°‹çµæœ
        """
        logger.info(f"ğŸ” [Retriever] å¤šæŸ¥è©¢æœå°‹: {len(queries)} å€‹æŸ¥è©¢")
        
        all_results = []
        seen_texts = set()  # ç”¨æ–¼å»é‡
        
        for query in queries:
            results = self.search(query, top_k=top_k, filters=filters)
            
            for r in results:
                # ä½¿ç”¨æ–‡æœ¬çš„å‰ 100 å­—ç¬¦ä½œç‚ºå»é‡éµ
                text_key = r["text"][:100] if r["text"] else ""
                if text_key and text_key not in seen_texts:
                    seen_texts.add(text_key)
                    all_results.append(r)
        
        # æŒ‰ score æ’åº
        all_results.sort(key=lambda x: x["score"], reverse=True)
        
        logger.info(f"âœ… [Retriever] å¤šæŸ¥è©¢æœå°‹å®Œæˆ: {len(all_results)} å€‹ä¸é‡è¤‡çµæœ")
        
        return {
            "queries": queries,
            "results": all_results,
            "total": len(all_results)
        }


def get_retriever() -> Retriever:
    """å–å¾—å…¨åŸŸ Retriever å¯¦ä¾‹"""
    global _retriever_instance
    if _retriever_instance is None:
        _retriever_instance = Retriever()
    return _retriever_instance


def reset_retriever():
    """é‡ç½®å…¨åŸŸ Retriever å¯¦ä¾‹"""
    global _retriever_instance
    _retriever_instance = None
