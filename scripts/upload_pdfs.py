#!/usr/bin/env python3
"""
PDF ä¸Šå‚³è…³æœ¬ - å°‡ PDF æ–‡ä»¶ä¸Šå‚³åˆ°çŸ¥è­˜åº«
"""

import os
import sys
import asyncio
import hashlib
from pathlib import Path
from typing import List, Dict, Any

# ç¢ºä¿è¼‰å…¥ .env æª”æ¡ˆï¼ˆä½¿ç”¨å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼‰
from dotenv import load_dotenv
_project_root = Path(__file__).resolve().parent.parent
_env_path = _project_root / ".env"
load_dotenv(_env_path)

# æ·»åŠ å°ˆæ¡ˆè·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent.parent))

from openai import AsyncOpenAI
from qdrant_client import QdrantClient
from qdrant_client.models import PointStruct, VectorParams, Distance


# é…ç½®
COLLECTION_NAME = "rag_knowledge_base"
EMBEDDING_MODEL = "text-embedding-3-small"
EMBEDDING_DIM = 1536
CHUNK_SIZE = 1000
CHUNK_OVERLAP = 200


async def extract_text_from_pdf(pdf_path: str) -> List[Dict[str, Any]]:
    """å¾ PDF æå–æ–‡å­—ä¸¦åˆ†å¡Š"""
    try:
        import fitz  # PyMuPDF
    except ImportError:
        print("è«‹å®‰è£ PyMuPDF: pip install pymupdf")
        sys.exit(1)
    
    doc = fitz.open(pdf_path)
    file_name = Path(pdf_path).name
    
    chunks = []
    
    for page_num in range(len(doc)):
        page = doc[page_num]
        text = page.get_text()
        
        if not text.strip():
            continue
        
        # åˆ†å¡Š
        words = text.split()
        current_chunk = []
        current_length = 0
        
        for word in words:
            current_chunk.append(word)
            current_length += len(word) + 1
            
            if current_length >= CHUNK_SIZE:
                chunk_text = " ".join(current_chunk)
                chunks.append({
                    "text": chunk_text,
                    "file_name": file_name,
                    "page_label": str(page_num + 1),
                    "chunk_index": len(chunks)
                })
                
                # ä¿ç•™ overlap
                overlap_words = current_chunk[-CHUNK_OVERLAP // 5:]
                current_chunk = overlap_words
                current_length = sum(len(w) + 1 for w in current_chunk)
        
        # è™•ç†æœ€å¾Œä¸€å€‹ chunk
        if current_chunk:
            chunk_text = " ".join(current_chunk)
            if len(chunk_text) > 50:  # è‡³å°‘ 50 å­—å…ƒ
                chunks.append({
                    "text": chunk_text,
                    "file_name": file_name,
                    "page_label": str(page_num + 1),
                    "chunk_index": len(chunks)
                })
    
    doc.close()
    return chunks


async def get_embeddings(texts: List[str], client: AsyncOpenAI) -> List[List[float]]:
    """æ‰¹æ¬¡å–å¾—å‘é‡"""
    response = await client.embeddings.create(
        model=EMBEDDING_MODEL,
        input=texts
    )
    return [item.embedding for item in response.data]


async def upload_pdf(pdf_path: str, qdrant: QdrantClient, openai_client: AsyncOpenAI):
    """ä¸Šå‚³å–®ä¸€ PDF"""
    print(f"\nğŸ“„ è™•ç†: {Path(pdf_path).name}")
    
    # æå–æ–‡å­—
    chunks = await extract_text_from_pdf(pdf_path)
    print(f"   æå–äº† {len(chunks)} å€‹å€å¡Š")
    
    if not chunks:
        print("   âš ï¸ ç„¡æ³•æå–æ–‡å­—")
        return
    
    # æ‰¹æ¬¡è™•ç† embedding
    batch_size = 20
    all_points = []
    
    for i in range(0, len(chunks), batch_size):
        batch = chunks[i:i + batch_size]
        texts = [c["text"] for c in batch]
        
        print(f"   æ­£åœ¨è™•ç† {i + 1}-{min(i + batch_size, len(chunks))} / {len(chunks)}...")
        
        embeddings = await get_embeddings(texts, openai_client)
        
        for j, (chunk, embedding) in enumerate(zip(batch, embeddings)):
            # ç”Ÿæˆå”¯ä¸€ ID
            content_hash = hashlib.md5(
                f"{chunk['file_name']}_{chunk['page_label']}_{chunk['chunk_index']}".encode()
            ).hexdigest()
            point_id = int(content_hash[:16], 16) % (2**63)
            
            point = PointStruct(
                id=point_id,
                vector=embedding,
                payload={
                    "text": chunk["text"],
                    "file_name": chunk["file_name"],
                    "page_label": chunk["page_label"],
                    "chunk_index": chunk["chunk_index"],
                    "source": "pdf_upload"
                }
            )
            all_points.append(point)
    
    # ä¸Šå‚³åˆ° Qdrant
    print(f"   ä¸Šå‚³ {len(all_points)} å€‹å‘é‡åˆ° Qdrant...")
    qdrant.upsert(
        collection_name=COLLECTION_NAME,
        points=all_points
    )
    
    print(f"   âœ… å®Œæˆ: {Path(pdf_path).name}")


async def main():
    # æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ éŒ¯èª¤: OPENAI_API_KEY æœªè¨­ç½®")
        sys.exit(1)
    
    # åˆå§‹åŒ–å®¢æˆ¶ç«¯
    openai_client = AsyncOpenAI(api_key=api_key)
    qdrant = QdrantClient(
        host=os.getenv("QDRANT_HOST", "localhost"),
        port=int(os.getenv("QDRANT_PORT", 6333))
    )
    
    # ç¢ºä¿ collection å­˜åœ¨
    collections = [c.name for c in qdrant.get_collections().collections]
    if COLLECTION_NAME not in collections:
        print(f"å»ºç«‹ collection: {COLLECTION_NAME}")
        qdrant.create_collection(
            collection_name=COLLECTION_NAME,
            vectors_config=VectorParams(
                size=EMBEDDING_DIM,
                distance=Distance.COSINE
            )
        )
    
    # å–å¾— PDF æª”æ¡ˆ
    if len(sys.argv) > 1:
        pdf_files = sys.argv[1:]
    else:
        # é è¨­æœå°‹ç•¶å‰ç›®éŒ„
        pdf_files = list(Path(".").glob("*.pdf"))
    
    if not pdf_files:
        print("ç”¨æ³•: python upload_pdfs.py file1.pdf file2.pdf ...")
        sys.exit(1)
    
    print(f"\nğŸ“š æº–å‚™ä¸Šå‚³ {len(pdf_files)} å€‹ PDF æª”æ¡ˆ\n")
    print("=" * 50)
    
    for pdf_path in pdf_files:
        if not Path(pdf_path).exists():
            print(f"âš ï¸ æª”æ¡ˆä¸å­˜åœ¨: {pdf_path}")
            continue
        
        await upload_pdf(str(pdf_path), qdrant, openai_client)
    
    # é¡¯ç¤ºçµ±è¨ˆ
    print("\n" + "=" * 50)
    info = qdrant.get_collection(COLLECTION_NAME)
    print(f"\nğŸ“Š çŸ¥è­˜åº«çµ±è¨ˆ:")
    print(f"   ç¸½å‘é‡æ•¸: {info.points_count}")
    print(f"   ç´¢å¼•ç‹€æ…‹: {info.status}")
    print("\nâœ… ä¸Šå‚³å®Œæˆ!")


if __name__ == "__main__":
    asyncio.run(main())
