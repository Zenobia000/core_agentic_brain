# OpenManus 專案與《AI 代理的上下文工程》原則符合度分析報告

**版本**: 1.0
**日期**: 2026-01-19
**分析員**: AI Architect

---

## 1. 總覽

本報告旨在將 `OpenManus` 專案的當前實現與其官方部落格文章《AI 代理的上下文工程：從構建 Manus 中學到的經驗》中闡述的核心設計原則進行比對。分析將圍繞文章中提出的六個關鍵「上下文工程」策略展開，以評估專案的理論符合度。

**總體結論**：`OpenManus` 專案成功地實現了文章中關於**外部化上下文 (Externalization)** 和**錯誤反饋 (Error Feedback)** 的核心思想，但在**動態作用域管理 (Dynamic Scope Management)** 的具體實現上與文章描述存在差異。

---

## 2. 核心原則符合度分析

### 2.1 原則一：圍繞 KV-Cache 進行設計 (部分符合)

- **文章描述**: 為了效率，應盡可能重複利用上下文，減少 LLM 的重算。
- **專案實現**:
    - **`max_observe` 參數**: `ToolCallAgent` 中的 `max_observe` 參數會截斷工具返回的過長輸出。這是一種有效的**摘要 (Summarization)** 形式，可以防止無關緊要的細節撐爆上下文窗口，間接有助於 KV-Cache 的有效利用。
    - **動態上下文注入**: `Manus` Agent 的 `BrowserContextHelper` 在處理瀏覽器任務時，會將當前頁面的相關信息進行格式化後注入到下一步提示中，而不是將整個網頁 DOM 放入上下文。這也是一種高效的上下文管理策略。
    - **核心記憶體模型**: 專案的基礎記憶體模型 (`self.memory.messages`) 是一個持續增長的列表。在每次 `think()` 調用中，大部分歷史記錄都會被重新發送。這與文章中提到的理想化 KV-Cache 利用策略存在差距，但透過上述的摘要和截斷機制進行了部分彌補。

### 2.2 原則二：用遮罩 (Masking) 而非移除來管理工具 (不符合)

- **文章描述**: 為了維持 LLM 對於可用工具集的穩定認知，應使用「遮罩」來暫時禁用工具，而不是從列表中徹底「移除」。
- **專案實現**:
    - `Manus` Agent 在與 MCP 伺服器互動時，其 `connect_mcp_server` 和 `disconnect_mcp_server` 方法會直接從 `self.available_tools` 集合中**添加或移除** `MCPClientTool` 實例。
    - 在每次 `think()` 調用時，Agent 會將當前 `available_tools` 列表的完整內容傳遞給 LLM。
    - 專案中**沒有發現「遮罩」機制**的實現。當前的方法是直接修改 LLM 在單次調用中看到的作用域，這與文章中提倡的「維持穩定認知」的策略有所不同。

### 2.3 原則三：將文件系統作為外部上下文 (完全符合)

- **文章描述**: 利用文件系統作為一種無限的外部記憶體，讓 Agent 能夠處理和管理持久化狀態。
- **專案實現**:
    - `Manus` Agent 的系統提示符 (`SYSTEM_PROMPT`) 明確地將一個工作區目錄 (`workspace_root`) 作為其初始上下文。
    - `PythonExecute`、`StrReplaceEditor` 等核心工具被設計為在這個工作區內操作文件。
    - 這完全符合將文件系統作為 Agent 的「外部記憶體」或「草稿紙」的設計哲學，使其能夠執行需要持久化狀態的複雜任務（如編寫和測試程式碼）。

### 2.4 原則四：透過摘要操縱注意力 (完全符合)

- **文章描述**: 使用摘要技術來濃縮信息，引導模型的注意力，同時保持上下文窗口的精簡。
- **專案實現**:
    - 如原則一所述，`max_observe` 參數和 `BrowserContextHelper` 都是此原則的直接體現。它們並非簡單地將原始信息塞入上下文，而是經過了**截斷**或**摘要提煉**，這是一種高級的注意力操縱技巧，確保 LLM 只關注當前決策最相關的信息。

### 2.5 原則五：保留錯誤以供模型適應 (完全符合)

- **文章描述**: 不要對模型隱藏錯誤。將工具執行失敗的錯誤信息反饋給模型，使其能夠從失敗中學習並修正策略。
- **專案實現**:
    - `ToolCallAgent.execute_tool` 方法中的 `try...except` 區塊是此原則的完美實現。
    - 當工具執行失敗時（無論是 JSON 解析錯誤還是執行時異常），該方法會捕獲異常，將其格式化為一條清晰的錯誤信息字符串（例如：`Error: Tool '...' encountered a problem: ...`）。
    - 這條錯誤信息隨後被作為一條 `tool` 消息添加到 `Memory` 中。在下一個 `think()` 循環中，LLM 會明確地看到它上一步的行動導致了什麼樣的錯誤，從而可以進行自我修正。

### 2.6 原則六：在 Few-shot 示例中引入多樣性 (不適用)

- **文章描述**: 為防止模型過度模仿，應在 few-shot 提示中提供多樣化的示例。
- **專案實現**:
    - `OpenManus` 的核心提示（如 `SYSTEM_PROMPT` 和 `NEXT_STEP_PROMPT`）是**指令 (Instruction)**，而非 **Few-shot 示例**。
    - 整個 Agent 的決策流程基於 LLM 強大的 **Zero-shot Tool-Calling** 能力，它依賴的是對工具功能描述的理解，而不是模仿示例。
    - 因此，該原則在當前的專案架構中並不適用。

---

## 3. 結論

`OpenManus` 專案的實現與其設計哲學高度一致，特別是在利用外部上下文、處理錯誤反饋和透過摘要管理注意力方面。這表明該專案在構建能夠從環境和自身錯誤中學習的、有彈性的 Agent 方面做得非常出色。

主要的差異點在於工具作用域的管理方式。雖然當前的「動態增刪」方法在功能上是可行的，但與文章中提出的「遮罩」理論相比，可能會在更複雜的多伺服器、動態權限場景下對模型的穩定性提出更高挑戰。這或許是未來版本可以進一步演進和探索的方向。


# OpenManus 上下文工程優化分析 (紅綠燈報告)

**版本**: 1.0
**日期**: 2026-01-19
**分析員**: AI Architect

---

## 1. 總覽

本報告基於《AI 代理的上下文工程》核心原則，針對 `OpenManus` 專案中未完全符合或有待優化的部分，進行深入分析。報告以「紅綠燈」形式，直觀展示當前實現的狀態、潛在風險及具體的優化建議。

- 🟢 **綠燈**: 完全符合設計原則。
- 🟡 **黃燈**: 部分符合，但存在優化空間。
- 🔴 **紅燈**: 未符合或實現方式與原則相悖，建議優先改進。

---

## 2. 優化分析表

| 狀態 | 原則/優化領域 | 當前實現分析 | 潛在風險/劣勢 | 建議的優化方案 |
| :--- | :--- | :--- | :--- | :--- |
| 🟡 | **原則一：圍繞 KV-Cache 進行設計** | Agent 的核心記憶體 (`self.memory.messages`) 是一個隨對話增長的列表，每次 `think()` 都會傳遞大部分歷史，對 KV-Cache 不友好。目前僅透過 `max_observe` 截斷工具輸出和 `BrowserContextHelper` 進行部分緩解。 | 1. **成本增加**: 隨著對話變長，每次 API 調用的 Token 消耗線性增長。<br>2. **性能下降**: 過長的上下文會增加 LLM 的處理延遲。<br>3. **上下文溢出**: 在極長的任務中，可能觸及模型的最大上下文窗口限制。 | **方案一 (短期)**: 實施滑動窗口 (Sliding Window) 記憶，只保留最近 N 輪的對話。<br><br>**方案二 (長期)**: 開發一個「記憶摘要 Agent」。該 Agent 可以在後台異步運行，定期將較早的對話歷史進行摘要總結，用一個精簡的摘要替換多輪的詳細對話，從而控制上下文總長度。 |
| 🔴 | **原則二：用遮罩 (Masking) 管理工具** | 當前實現是**直接修改** `self.available_tools` 列表。`connect_mcp_server` 會向列表**添加**工具，`disconnect_mcp_server` 會從列表中**移除**工具。LLM 在每次調用中看到的是一個動態變化的工具全集。 | 1. **模型認知不穩定**: LLM 可能會因為工具集頻繁變化而「困惑」。例如，模型可能剛學會使用某個工具，但下一次調用時該工具就消失了，影響決策的連貫性。<br>2. **提示詞注入攻擊風險**: 如果工具的增刪來自於外部輸入，可能存在惡意用戶透過註冊/註銷工具來操縱 Agent 行為的風險。 | **方案一 (推薦)**: **實現真正的遮罩**<br>1. 在 Agent 內部維護一個包含所有可能工具的「主列表」。<br>2. 在 `think()` 方法中，根據當前的權限、上下文或策略，從主列表中**過濾**出當前「已啟用」的工具集，再傳遞給 `llm.ask_tool()`。這樣，工具的註冊是持久的，只是其可用性是動態的。<br><br>**方案二 (輕量級)**: **在提示中標記狀態**<br>始終向 LLM 提供完整的工具列表，但對於當前不可用的工具，在其描述中動態添加「(當前不可用)」或「(需要特定權限)」等文本，引導 LLM 不去使用它們。 |
| 🔴 | **原則六：Few-shot 示例的多樣性** | 專案目前完全採用 **Zero-shot** 模式，依賴指令和工具描述來引導 LLM，並未設計 Few-shot 示例機制。這本身是一種有效策略，但缺乏處理特定複雜任務的「專家經驗」。 | 1. **處理複雜工作流能力受限**: 對於需要多個工具以特定順序、特定方式組合才能完成的複雜任務，Zero-shot 可能會陷入反覆試錯，效率低下。<br>2. **可控性較差**: 對於某些需要精確控制輸出格式或行為模式的場景，缺乏範例引導會使得 LLM 的輸出更難預測。 | **方案一**: **引入 `PromptManager`**<br>1. 建立一個 Few-shot 示例庫，每個示例都是一個針對特定任務（如「分析並修復 Python 程式碼中的 bug」）的 `{input, thought, tool_calls, observation}` 鏈。<br>2. 在 `think()` 流程開始前，引入一個 `PromptManager`，它可以根據用戶的初始請求或當前任務的分類，從庫中動態選擇最相關的一或兩個示例，並將其插入到發送給 LLM 的上下文中。<br><br>此方案可以作為對現有 Zero-shot 機制的有力補充，在特定場景下「教」會 Agent 如何更高效地解決問題。 |

---

## 3. 結論

`OpenManus` 當前的架構功能強大且在多個方面與其設計哲學保持一致。然而，透過引入**記憶摘要機制**、實現**工具遮罩**而非直接修改，以及在未來為複雜任務補充 **Few-shot 示例管理器**，可以顯著提升其運營成本效益、長期穩定性和處理複雜任務的效率，使其更接近一個真正企業級的 Agentic 作業系統。
